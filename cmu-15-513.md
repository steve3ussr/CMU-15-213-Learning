# Number's Storage

## Bit Operator

- `&, |, ^, ~`, 位运算
- XOR: 相同为0, 不同为1
- `&&, ||, !`, 逻辑运算, 而且是短路的
- `<<`左移, 高位被低位取代, 低位被0填充: `0b0110,0010 << 3: 0b0001,0000`
- `>>`右移, 低位被高位取代, 高位被0或1填充
  - 逻辑右移: `0b1010,0010 >> 3: 0b0001,0100`
  - 算数右移: `0b1010,0010 >> 3: 0b1111,0100`



## Two’s Complement

unsigned vs signed (Two’s complement)

- `uint8`, 这很简单
- `int8`, 第一位为符号位, 0时正数, 1时负数
- `int8`表示

```
0b01111 = 15
0b11111 = -(0b0000+1) = -1
这个方法不好记, 另一个方法是, 如果最高位是1, 把它看成-2^5
0b11111 = -2^5
          +2^4 +2^3 +2^2 +2^1 +2^0 
        = -1
```

在C中, int占4bytes, 所以如果`int x = 0bFFFFFFFF`, 得到的就是-1

## Number Expand & Truncate

### Expanding

如果是uint, 那就直接填0好了; 如果我要将一个int8扩展为int16, 该如何做呢? 显然的:

- 对于正数, 什么都不用管, 在前面补0就好了
- 对于负数, 假如是从int8扩展为int9, 原本的第一位是`-2^7`, 现在变成了`+2^7`, 因此需要一个`-2^8`来抵消, 也就是在前面补一个1;
- 以此类推, 从int8到int16, 前面所有的数字都是1

**总结: 将原本的第一位复制到前面所有的位置上**



### Truncating

如果是uint: 

```
uint5   -> uint4
0b10100 -> 0b0100
20      -> 4

uint6    -> uint4
0b100100 -> uint0100
40       -> 4

Act like 40%(2^4) = 4
```

如果是正的int, 根据uint的规矩, 从uint n 到uint 4, 其实是对2^3取余. 

对于负的int, 该规律也一样, 对2^3取余: 只不过最终得到的是负数, 例如-29对8取余得到-5. 



## Add (Minus), Mul, Div, Pos/Neg

不管是有int还是uint, 都按照正常加法做就好了, 溢出也没关系, 溢出了也是对的. 

举例, -6加-3

```
-6   1010
-3   1101
---------
-9  10111 -> truncate -> 0111=7
```

这是正常的, -9超过了`[-8, 7]`的范围, 所以溢出成了7

---

乘法也是一样的, 例如int下, 5X5

```
5    0101
5    0101
----------
     0101
   0101
   -------
   011001 = 1001 = -7
```

btw, 这还说明了如果需要将一个数字x4, 只需要左移2位

---

除法就不太一样了, 是右移; 但对于int中的负数, 左侧补充的值应该能保持符号, 所以在左侧填充符号位, 例如: 

```
-6    1010
right shift 1 bit:
-3    1101
```

但如果要对-3/2呢?我们会得到

```
-3 1101  -> -2 1110
```

在C中, 计算这个除法时, 编译器会先给1101+1 = 1110(-2), 右移1位得到1111(-1). 这个偏移量是向0靠拢. 

在其他语言, 可能得到-2

---

取反+1, 例如 

```
            6    0110
flip all bits    1001
            +1   1010=-6
```

---

如何检测溢出?

- 对于uint, 如果x+y结果>=x是正常的, 如果x+y<x不正常
- 对于int, int s=x+y
  - 如果x>0, y>0, 但s<=0时发生正溢出
  - 如果x<0, y<0, 但s>=0时发生负溢出

## Byte Ordering

> Big Endian, Little Endian

- 大端序：就像我们阅读一样符合直觉，地址低位的是开头，高位的是结束。常见于：**网络IO**
- 小端序：恰恰相反，一个数字的低位在地址高位，高位在地址低位；优点是性能好

> test_print_bytes.c

这个程序中，可以逐字节地查看内存，比如11451，对应int: `0x0000 2CBB`，但在内存中的存储情况为：

```
ADDR               VALUE
------------------------
000000d7c97ff77c    0xbb
000000d7c97ff77d    0x2c
000000d7c97ff77e    0x00
000000d7c97ff77f    0x00
```

## Float

> a website shows float clearly: [https://gregstoll.com](https://gregstoll.com/~gregstoll/floattohex/)

小数点后第一位为$1/2$，第二位为$1/4$，以此类推，第i位为$\displaystyle\frac{1}{2^i}$。

但这么做有个问题，如果float固定只占32/64字节，小数点前的数字太少，则能表示的范围太少；如果增加表示范围，则小数点后的精度又不够，所以如何trade off是个问题。

关键就是要让小数点浮动起来，大概这也是命名为浮点数的原因。

---

### Normalized

float占32位，其中：

- S: Sign, 1 bit
- E: Exponent, 8 bits
- M: Mantissa, 23 bits

---

将数字转化为浮点数的步骤：

1. 将一个数字表示为2进制的形式，例如65.125，等于`0b0100 0001.0010`
2. 将这个数字normalized为`[1, 2)`之间的形式，或者说是科学计数法，`1.00 0001 0010 X 2^(6)`。注意，这里的偏移量**可正可负**
3. 小数点后的数字放在M区域内，这很正常
4. normalize后小数点前的1被省略了，这很牛逼——这也是为什么一定要让数字在`[1, 2)`区间内的原因
5. 指数的8位，如果用无符号数可以表示`[0, 255]`，如果用有符号数可以表示`[-128, 127]`
6. 有没有什么方法，能让表示范围更大呢？如果我固定地给指数+127的偏移量，这样指数的范围是：`[-127, 128]`，偏移后的范围刚好是8位u short的范围
7. 事实上，E域全0和全1是有特殊含义的，所以能表示的真实指数范围是`[-126, 127]`
   1. E全1,  M全0：根据符号位，可能是正无穷或者负无穷
   2. E全1，M非全0：NaN
   3. E全0：代表非规格化


---

一个实际的例子：

$5.75=1.0111\times2^2$

- 符号位 0
- 指数为2+127，无符号8位
- 尾数23位

最终答案是`0x40B8 0000`

---

这个例子有问题，无法表示0

### Denormalized

为了能表示0，令上面例子中的$5.75=0.10111\times2^3$。相比于规格化，非规格化浮点数的变化为：

- 为了表示相同范围的数字，非规格化需要给指数偏移126
- 可以表示0，而且有+0和-0



### Norm <-> Denorm

- 从Norm到Denorm，需要M域右移1位，并在最前面补0；E域不用动
- 从Denorm到Norm，也仅仅需要将M域左移1位

### Special Cases

之前提到了一点，E域全0和全1代表特殊情况。

- E域全1，M域全0：加法或者乘法溢出，代表$\pm\infty$
- E域全1，M域非全0：NaN



### Operations

- 加、减、乘都不能保证结果在区间内，可能会溢出；
- 更重要的是结果rounding，如何将float转化为int，或者是固定舍入到小数点后几位
  - to zero
  - down to -infinity
  - up to +infinity
  - near even



### Other Properties

- Commutative, 交换律
- NOT Associative, 结合律。在计算前会先对齐小数点，此时存在大数吃小数的情况，例如:
  - `1e2+(1e-10 - 1e-10)=1e2`
  - `(1e2+1e10)-1e10=0`
  - `(1e20*1e20)*1e-20=+inf`
  - `1e20*(1e20*1e-20)=1e20`
- 基于相同的原因，乘法也不满足分配律
- `int x; (int)(float) x`会导致精度损失，因为float-M只有23位，导致int的后8位被truncate掉了



# Machine-Level Programming: Assembly

## Basic

- 编译器：和CPU的指令集合作，把程序变成各种指令
- PC: Program Counter，告诉我下一个指令的地址
- 寄存器：像是内存，但不是通过内存地址来访问，而是通过名字来访问
- Condition codes：只有几个bits的寄存器，用来存储最近的一些指令运行结果是什么，可以用来实现条件分支
- cache：没有直接访问的方法，由CPU来处理

## Compile Source Code to Asm

按照书中的例子去做，但由于机器不同、gcc版本不同、gcc设置不同，生成的汇编代码区别也很大。使用的gcc命令行为`gcc -Og -S sum.c` 其中：

- g代表debugger，适合这门课，使得asm和源代码基本一致，没有做花里胡哨的优化
- S代表stop

生成的结果中:

- 百分号开头的代表寄存器的名字
- pushq，popq：和栈相关
- movq：移动
- call：调用某个procedure
- ret：return
- 句点开头：一些其他东西，可以暂时忽略

更详细的例子，例如  `*dest=t`，变成asm是  `movq %rax, (%rbx)`，其中rax里存储着t的值，rbx是dest的地址，（rbx）代表dest的实际内容

## Disassembly

反汇编，Disassembler从object code倒退回assemble code, 两种方式： objdump和gdb：

```
objdump -d obj.o > obj.d
```

或者用`gdb obj.o` 打开一个object code，然后用`disaasemble <func name>` 查看某个函数的反编译结果

## Register

寄存器的名字中：

- %r+字母代表64位，%rax
- %e+字母代表对应的32位，e代表extend（相对16位），%eax
- %ax代表16位，包括%ah和%al，分别代表高低两个字节

两个特殊的寄存器，最好不要操作他们：

- %sp，stack pointer，指向函数栈
- %ip，instrction pointer，当前正在执行的指令的地址

## Calc RAM Address

地址偏移的几种方式: 

1. offset, `0x8(%rax)`
2. Add, (%rax, %rbx)
3. base + index * scale（一个数据所占的内存大小），（%rbx, %rcx, 8）
4. 0x80(, %rdx,2) = 2*%rdx + 0x80

## Assembly Instructions

movq指令中，只有5种情况：

1. `movq %0x3, %rax`, a = 3;
2. `movq %0x3, (%rax)`, *a = 3;
3. `movq %rax, %rbx`, b = a;
4. `movq %rax, (%rbx)`, *b = a;
5. `movq (%rax), %rbx`, b = *a

可以给寄存器做加法，例如 `8(%rax)` 会给rax里的地址+8，再去寻找值

---

指令leaq，很有意思。她的形式是`leaq (内存寻址操作), 寄存器`, src的内存寻址操作完成后，并不会真的去访问对应的内存内容，而是把内存地址直接写入dest寄存器。编译器经常用该指令完成一些操作，例如：

```
leaq 7(%rdx, %rdx, 4), %rax
```

- 其中%rdx存储的并不是一个指针，而是一个普通的值x
- 该指令首先计算src，计算出7+x+x*4=5x+7
- 该指令并不从5x+7对应的内存地址获取值，而是直接将计算结果存入%rax

---

addq src，dest ：dest = dest + src



## Flow Control: Condition Code, Conditional Jump

几个特殊的标志位，标记了状态信息，不能直接操作：

- CF，carry flag (for unsigned)，进位，例如两数相加溢出会影响这个flag
- ZF，Zero flag
- SF，Sign flag (for signed)
- OF，Overflow flag (for signed)

有些指令不会把计算结果放在寄存器，但是会改变flag states，例如：

- CMP b, a 像是计算a-b
- test b, a，像是计算a&b；实际中常见test %rax,%rax，用于判断正负和0

不能直接从condition code中读取，但通过set指令（一系列set指令），可以根据condition code改变寄存器的一个低位byte

例子：当我return x>y时发生了什么？

1. cmp y, x，如果x>y，SF会变成1，OF最好是0
2. setg %al，将%rax-%eax-%ax-%al置0/1
3. movzbl %al, %eax，零扩展，将al前面的3个字节置0。修改eax时，会自动把rax的前4字节也置0

---

通过各种语句设置了状态码后，通过“条件跳转”可实现条件分支。

- jX系列指令可以根据conditon code跳转
- C中可以通过goto来跳转
- 汇编中，通过`.name`的方式加标签；使用`jump <label name>`的方式可跳转到这个标签
- 或者通过`jump *(%rax)`的方式，跳转到rax指向的内存地址继续执行代码

---

频繁的跳转对CPU流水线/分支预测不利，跳转会影响流水线预读取的指令，最坏的情况下需要很多个时钟周期才能继续运行。

一个优化方法是条件移动，两个条件分支我都计算，最后根据条件，选择一个值存入寄存器。这样的话，CPU有一长串连续的指令可以运行，而不是运行一段时间就停下来。——**尽管如此，这只适用于简单的计算**。

## Flow Control: Loops

### do-while

例子：计算int中的1-bit有多少个，查看汇编代码。C代码的例子包括do-while和loop两个版本：

```c
void do_while (int x) {
    int res=0;
    do {
        res += (x>>31) & 1;
        x <<= 1;
    } while (x);
    printf("There are %d 1-bit in x\n", res);
}

void do_while_goto(int x) {
    int res=0;
    exec:
    res += (x>>31) & 1;
    x <<= 1;

    if (x) goto exec;
    printf("There are %d 1-bit in x\n", res);
}
```

汇编后的代码基本一致，其中核心部分为：

```assembly
do_while:
	subq	$40, %rsp
	movl	$0, %edx
.L2:
	movl	%ecx, %eax
	shrl	$31, %eax
	addl	%eax, %edx
	addl	%ecx, %ecx
	jne	.L2
	leaq	.LC0(%rip), %rcx
	call	printf
	nop
	addq	$40, %rsp
	ret
```

其中值得注意的是：

- 操作rsp-40，分配栈空间
- edx 为res，初始值为0；ecx为x
- SHR是逻辑右移，左侧为0；SAR是算术右移；
- add ecx, ecx实现了左移；
- add ecx, ecx的结果将改变conditional code，如果结果非0，就会跳转到L2

### while

对于常见的while循环，写成goto形式通常是：

```c
goto check;
loop:
    loop-expression;
check:
    if (condition) goto loop;
```

或者：

```c
if (!cond) goto done;
loop:
    loop-expression;
    if (test) goto loop;
```

### for

```c
init;
goto check;
loop:
    loop expression;
check:
    if (cond) goto loop;
finally expression;
```

### switch

如果switch中的case数量较多，而且值的跨度不大，就会使用跳转表的数据结构存储每个case block。例如：

```c
switch (x) {
case 1: case1_block; break;
case 2: case3_block;
case 6: case6_block; break;
default: def_block;
}
```

- 在汇编中，首先判断x和6的关系，如果uint res = x-6大于0（x大于6，或者x<0），直接跳转到默认情况。
- 各个case执行的代码都储存在内存中，内存的地址（代码块的指针）存储在一个jump table中
- 程序根据case的值确定index，从jump table根据base + index*length，确定执行哪一个代码块的指针；

有一下几种特殊情况：

1. case很稀疏，比如值包括1，100，1000000，这时候就会转化为if-else，而不是jump table；
2. case值的范围不靠近0，比如从100-110；或者跨越0，比如从-5到5。编译器会给case number offset，使得从0开始



## Procedure

有时我们需要在过程P中调用过程Q，此时将会用到栈。栈帧中存储着一些寄存器、局部变量等。

栈的底部是在某一个高地址位，栈的元素扩张是向低地址方向扩张；rsp寄存器的值始终指向栈的顶部（低地址）。如果栈需要扩张，rsp的值就会减少；如果栈需要缩小，rsp的值就会增加。

栈帧通常由两个指针分隔，rbp和rsp

- rsp指向高地址
- [Optional] rbp，base pointer指向当前帧的低地址 

**汇编中，过程跳转的控制指令：**

- call做了三件事
  - 减少栈指针%rsp 8（扩张）
  - 将call的下一行的指令地址push入最新扩张的栈帧中；这是从其他过程中返回时，当前过程需要执行的下一步
  - call 后面的值是要执行的指令位置，%rip（instruction pointer，通常是当前执行指令的地址）将被设为该值
- ret
  - 假定栈的顶部是要跳转的指令地址，pop该地址并存入rip
  - rsp+=8

**汇编中，参数传递的方式：**通过6个寄存器来传递前6个参数（通常是够用的），否则这些参数就会存储在栈中。

---

一些其他知识：

- 编译器通常会在栈上分配比需求大一些的空间，这是为了内存对齐之类的
- 如果一个参数不能仅通过寄存器来传递，就会存储在栈上 
- 编译器会通过sub和add rsp来分配和释放内存

---

根据约定俗成的规则，寄存器分为caller-saved和callee-saved。他们的意思是：

- P调用Q时，Q必须保证callee-saved寄存器内容不变，比如不改变他们的值，或者将其pushq并最终popq
- caller-saved的这些寄存器，必须被caller妥善保存（pushq），因为callee会改变寄存器的值

- 对于caller：不应该把局部变量储存在寄存器上，因为callee可能会改变该值
- 对于callee：如果有临时变量，那必须存储在栈上；当运行结束时，栈必须复原



## Data: Array, Struct

C中关于array的小知识

- 可以用`int *`来传递数组的地址
- 如果确定长度的话, 建议用定长数组, 包括一个定义长度的define宏, 以及一个`typedef int row[num_col]`, 这样的话定义array可以这样写: `row r1 = {1, 1, 4, 5, 1};`
- 通常我们先遍历第一行, 然后第二行...在内存中, 也是这样的排列顺序: `A00, A01, A02, A03, A10, A11, A12`
- 如果是定长数组, 编译器会优化, 在计算地址偏移量时直接左移; 如果不知道长度就需要用乘法, 而乘法是一种性能开销很大的指令

---





---

内存对齐: 很多计算机系统会对内存地址做限制, 例如现在有一个int类型, 则他的内存地址必须是4的倍数; 如果有一个char类型, 他的内存地址必须是1的倍数. 

如果我现在定义一个struct, 包含一个char和一个int, 在分配内存时会是char-3个空白的bytes-int.





## Advance

### 内存模型

- 内存中最高位为栈底
- 从低向高依次是：
  - text：可执行的代码
  - data：静态全局变量
  - heap：动态分配变量，malloc
  - shared lib：通用的可执行代码，printf等
  - stack：局部变量



### Buffer Overflow

- 如果index超过数组的实际范围，就可能会污染内存
- 如果数据超过缓冲区（要看汇编中实际分配了多少），会造成segment fault
-  在书上的例子中，caller调用callee前，会在caller栈帧末尾记录应该返回的地址（caller中call的下一行）；但由于callee中内存越界了，改变了这个返回地址；所以程序会无法继续运行。
- 如果用一个函数地址替换掉caller的返回地址，就可实现代码注入攻击

---

Solution：

1. 增加一个长度参数，限制缓冲区大小
2. 栈随机化：栈底不从0x7f开始，而是偏移一段
3. 标记某一处内存为not-writable
4. stack canary (非常安全): 默认启用，在caller的返回地址之后，又插入了空白代码和canary；如果callee结束后canary的值发生变化，则认为存在溢出，直接报错. 汇编形式大概是`mov %fs:40 %rax`. 
5. 以上手段都影响栈，而没有影响全局变量和代码区。面向返回编程：寻找代码区的ret指令，改变原函数的行为



### Union

一个非常神奇的数据结构，类似struct，但实际分配的内存为所有children中所占内存最大的一个。可以用来：

- 强制转换数据类型（例如int和float）



## ELF文件结构：GOT & PLT

动态链接得到的可执行文件并不包含外部函数的代码，而是在**运行时**将动态链接库（若干外部函数的集合）加载到内存的某个位置，再在发生调用时去链接库定位所需的函数。

GOT 全局偏移量表（**G**lobal **O**ffset **T**able）

- 用来存储外部函数在内存的确切地址
- GOT 存储在数据段（Data Segment）内，可以在程序运行中被修改。

PLT 全称是程序链接表（**P**rocedure **L**inkage **T**able）

- 存储外部函数的入口点（entry），GOT 表中对应条目的地址
- **PLT 存储在代码段（Code Segment）内，在运行之前就已经确定并且不会被修改**，所以 PLT 并不会知道程序运行时动态链接库被加载的确切位置。

不直接确定外部函数地址，分两个表的原因：

1. 如果在运行一开始就确定所有外部函数，可能会启动慢
2. GOT相当于lru cache，如果首次调用某个函数会通过PLT查找对应的GOT条目，并把解析出的外部函数地址存入GOT
3. 如果多次调用某外部函数，直接到GOT中查表



# CPU Architecture

## Y86-64

### 指令

只操作8 bytes 整数.

- movq: 根据 src 和 dst 分成若干种, i-instance, r-register, m-memory
- 地址计算是 base+offset
- 整数操作计算指令
- 跳转 (同x86)
- call, ret
- pushq, popq
- 没有普通mov,只有cmov (conditional)
- 指令要么附带2个寄存器id, 要么不带; 如果只用到一个寄存器, 那另一个置F
- 出现地址的时候应该采用小端序

和x86的不同: 

- add等操作只能用2个寄存器而不是用i
- subq会设置flags



## HCL，硬件设计

- 逻辑门是数字电路的基本计算单元, 或门/与门/非门. 输入的1和0是通过高低电平控制的; 

- 多个逻辑门可以组成计算块/组合电路, 并且这个电路必须是无环的

- mux: 根据控制信号，从多个源中选择一个

- 硬件寄存器：只有时钟信号为上升沿时，输出才会变成和输入一样；此外将会一直保持该输出；**这可以让硬件寄存器储存值**

- 寄存器文件（程序寄存器）：通常有多个输入输出，这样在一个时钟周期内就可以并行多个IO

- 内存：输入地址、数据输入、读/写信号，时钟；输出数据和error；

  - **写：在上升沿**将数据输入写到内存上
  - **读：假设为一个组合逻辑**，输入地址+读信号，可能输入error或者数据

  ---
  
  省流版：只有以下东西是在上升沿才发生变化，其他的都看作瞬间发生：
  
  - 硬件寄存器
  - 寄存器文件/内存的写
  
  ---
  
  各种颜色和形状：
  
  - 白色方框：时钟寄存器
  - 浅蓝色方框：硬件单元
  - 灰色圆角矩形：控制逻辑块，从一组信号源中选择，或者计算Bool函数
  
   
  
  
  
  

## SEQ，非Pipelined

一条指令包括几个阶段：

- fetch, 从PC读opcode，增加PC
- decode: 读最多两个register（可以只读rB）
- execute: 把两个数字送进ALU计算，并更新CC
- access memory：
- write back: 最多写回2个结果到Register，E用来写ALU Execute的值，M用来写从Memory读出的值；**dstE和dstM在decode阶段指定**
- PC update：可能来自fetch时更新的valP；也可能是valC指定的地址；也可能是valM里的返回地址 **这里可以引入分支预测**

![image-20250226213806606](C:\Users\steve3ussr\AppData\Roaming\Typora\typora-user-images\image-20250226213806606.png)

![image-20250226214033646](C:\Users\steve3ussr\AppData\Roaming\Typora\typora-user-images\image-20250226214033646.png)

*以rrmovq为例:*

1. [fetch] 从PC指向的内存位置读1字节, 前后4 bit分别写给icode和ifun
2. [fetch] 从PC+1指向的内存位置读1字节, 前后4 bit分别写给rA, rB这两个寄存器操作数指示符; (fetch的时候也有可能取出一个8B常数 valC)
3. [fetch] 计算出valP, 更新PC; 这里增加的值由一条指令的长度决定
4. [decode] 从寄存器读值, 读rA到valA
5. [execute] 实际上什么都不用干, 给valA+0到valE
6. [access memory] *(如果这里做了什么的话, 会把值读入valM)*
7. [write back] valE写回到rB
8. valP更新给PC

---

```
rmmovq rA, D(rB)
fetch:
	icode:ifun <- M1[PC]
	rA:rB <- M1[PC+1]
	valC <- M8[PC+2]
	valP <- PC+10
decode:
	valA <- R[rA]
	valB <- R[rB]
execute: 
	valE <- valB + valC  # valC=D, literally
access memory:
	M8[valE] <- valA
write back:
	pass
PC Update:
	M[PC] <- valP
```

---

```
iaddq V, rA
fetch:
	icode:ifun <- M1[PC]
	rA:rB <- M1[PC+1] # not sure if I can only read 1 of them
	valC <- M8[PC+2]
	valP <- PC+10
decode:
	valA <- R[rA]
exec:
	valE <- valA + valC
access memory: 
	pass
write back:
	R[rA] <- valE
PC Update:
	PC <- valP
```

## SEQ, pipelined

如果在一个CPU时钟内完成一条指令的所有部分，将会非常耗时。因此引入了pipeline：increase throughput, also increase latency. 

| t0   | t1   | t2   | t3   | t4   |
| ---- | ---- | ---- | ---- | ---- |
| A    | B    | C    |      |      |
|      | A    | B    | C    |      |
|      |      | A    | B    | C    |

如上图所示，将计算分成ABC三个阶段，可以像流水线一样执行指令。

cons:

- 时钟周期不能太短，否则计算不完
- **不一致的划分**：ABC所需时间可能不等
- **pipeline过深**：pipeline寄存器的延迟会成为影响throughput的重要因素；分支预测失败的惩罚也更大

---

> 如何实现pipeline-

1. PC计算提前（这样可以早些处理下一个指令），而是提前到fetch阶段，根据上一个指令的valC/valP/valM动态地计算结果；
2. 引入**流水线寄存器**（with **upper prefix，prefix代表在什么阶段之前**）
3. **lower case prefix指的是某个阶段刚刚计算出来的值**
4. dstE和dstM会在流水线中穿梭，直到W阶段才派上用场
5. 可以根据指令来预测下一个指令的PC
   1. call, jmp: valC
   2. 大部分: valP
   3. ret: 由于caller和callee成对出现，因此在硬件中有一个不可见的栈用来储存caller中ret下一条的PC；在csapp中假设不存在这种硬件
   4. conditional jump: 有多种预测的策略



---

> 如何实现pipeline

以上pipeline-存在两种hazard：

1. data hazard: 下一条指令使用上一条指令的运行结果
2. control hazard: 一条指令要确定下一条指令的位置，如ret，call等

例如：

```
irmovq $10, %rdx
irmovq $3,  %rax
addq %rdx, %rax
```

如果直接pipeline会有问题，因为存在数据依赖，addq在decode阶段需要前两个指令的write back都结束。

- 一种避免data hazard的方法是，在执行完前两条指令后插入3个nop，什么都不做；
- 如果只插入2个nop，add在decode阶段读取的rax的值将是mov前的旧值；
- 如果只插入1个nop，add在decode阶段读取的rdx的值也将是mov前的旧值；

| stage      | irmovq $10, %rdx                       | addq %rdx, %rax               |
| ---------- | -------------------------------------- | ----------------------------- |
| Fetch      | icode:ifun, valC=10, rB=rdx, valP=PC++ | icode:ifun, rA=rdx, rB=rax    |
| Decode     | valB = R[rB]                           | valA=rdx, valB=rax, destE=rax |
| Execute    | aluA=valC, aluB=0, dstE=rB, E=aluA+0   | valE=valA+valB                |
| Memory     | pass                                   | pass                          |
| Write Back | R[rB]=valE                             | R[rax] = valE                 |

Stalling: 当pipeline发现某个指令decode阶段所需的reg在其他正在运行的指令的E, M, W阶段会改变，就会block当前指令的decode；这个指令在全周期的运行情况可能是：`FDDDEMW`。这种方式相当于暂停了pipeline，性能较差。

Forwarding/Bypassing：与其等到W阶段才更新寄存器，不如在E阶段执行之后，就将valE存入p_valE（同时还会标记p_dstE），同时转发到 reg file 的E端口；这样下一条指令就可以直接从E读取更新后的值；同样的道理，也可以转发到寄存器文件读出的valA和valB；

**5种可能的转发源：**

- 如果某个指令的D和其他指令的W在同一个时序，可以用W_valE和W_dstE（指明寄存器）来forward；
- 同理如果D和M重合，也可以用M_valE和M_dstE；也可以替换成e_valE和e_dstE；
- 如果需要的是内存相关的值，可以用W_valM/W_dstM，或者m_valM/m_dstM

**2个转发目的地：valA, valB**

---

尽管如此，这种forwarding不能用于处理跨时间的hazard，例如上一条指令的M结果不能转发到下一条指令的D阶段。解决方法是stalling+forwarding，拖延一些周期；这种方法也叫load interlock（加载互锁）；

- add指令在D阶段需要读取rax，但mrmov最早在m时才会读取出rax正确的值
- 将add的D阶段暂停掉，这样利用m_dstM=rax，m_valM=*刚读出来的值*，可以让add指令在D阶段读取出正确的rax值
- D阶段包括两部分：从寄存器文件中读取；然后Sel+FwdA和FwdB单元决定使用什么值；**只要在D这个时钟周期结束前计算出e_val和e_dst，下一个时钟周期的上升沿E寄存器就能读取到正确的值，所以在D阶段读错了没关系，只要在E阶段开始前（E寄存器）的值正确就行**。
- 不会影响时序的原因是：FwdB和Sel+FwdA在这里被假设为基本没有延迟，至少是和时序无关，所以e产生的值会立刻被传播到E寄存器前；只要e_信号是在上升沿之前产生的就没问题

|              | F    | D    | E         | M    | W    |      |      |
| ------------ | ---- | ---- | --------- | ---- | ---- | ---- | ---- |
| mrmov v, rax | F    | D    | E         | M    | W    |      |      |
| add v, rax   |      | F    | D         | E    | M    | W    |      |
| add v, rax   |      | F    | D (stall) | D    | E    | M    | W    |





control hazard只会在ret和条件跳转的时候发生。

- 如果发现conditional jump预测错误，就把读错的指令stall，直接接bubble；然后回去读另一个分支的指令；
- 



### 异常处理

- 在一个时钟周期内，可能有多个指令异常：pipeline上最深的指令引起的一场优先级最高
- 如果预测分支失败，当前分支上出现的应该被取消
- 出现异常时会更新stat，从而禁止后续的指令更新Flags，reg，mem
- 可能产生异常：
  - halt指令
  - 非法指令
  - F或者M的地址非法

## PIPE

### Fetch

- 条件跳转失败时：从这里读出valP的值，指向下一条指令的地址；但暂时不知道为什么valP的值储存在M_valA中？
  - 如果某个时候取出一个条件分支，则必须等待E执行之后才能知道哪个分支是正确的，因为在E阶段执行后，CC才会发射e_Cnd更新M寄存器；由于csapp中的PIPE选择always taken策略（总是跳转），因此如果预测失败，需要使用valP作为下一条指令。
  - 没有任何一条指令同时需要valP和valA，**因此把valP的值合并到valA**，并由各阶段根据当前执行的指令来选择valA的值实际上是valA还是valP
  - 为什么使用M_Cnd而不是e_cnd呢？因为E阶段的ALU和F阶段的指令内存都是只在上升沿更新值，如果使用e_cnd，Fetch阶段也读不到值了，因为错过了上升沿
- 如果是ret指令，为什么下一条指令在W_valM中?
  - ret时，从%rsp指向的内存地址上读取内存，内存的内容是下一条指令的地址
  - 由于Fetch和Access Memory都需要在上升沿触发，所以不能使用m_valM，只能使用W_valM

```
################ Fetch Stage     ###################################

## What address should instruction be fetched at
word f_pc = [
	# Mispredicted branch.  Fetch at incremented PC
	M_icode == IJXX && !M_Cnd : M_valA; 
	# Completion of RET instruction
	W_icode == IRET : W_valM;
	# Default: Use predicted value of PC
	1 : F_predPC;
];

## Determine icode of fetched instruction
word f_icode = [
	imem_error : INOP; <!-- 如果Fetch阶段发现指令内存异常，就NOP-->
	1: imem_icode;
];

# Determine ifun
word f_ifun = [
	imem_error : FNONE; <!-- 如果Fetch阶段发现指令内存异常，就NOP-->
	1: imem_ifun;
];

# Is instruction valid?
bool instr_valid = f_icode in 
	{ INOP, IHALT, IRRMOVQ, IIRMOVQ, IRMMOVQ, IMRMOVQ,
	  IOPQ, IJXX, ICALL, IRET, IPUSHQ, IPOPQ };

# Determine status code for fetched instruction
word f_stat = [
	imem_error: SADR; <!-- Stat: Invalid mem addr -->
	!instr_valid : SINS; <!-- Stat: Invalid instruction -->
	f_icode == IHALT : SHLT; <!-- HALTEN SIE -->
	1 : SAOK;
];

# Does fetched instruction require a regid byte?
bool need_regids =
	f_icode in { IRRMOVQ, IOPQ, IPUSHQ, IPOPQ, 
		     IIRMOVQ, IRMMOVQ, IMRMOVQ };

# Does fetched instruction require a constant word?
bool need_valC =
	f_icode in { IIRMOVQ, IRMMOVQ, IMRMOVQ, IJXX, ICALL };

# Predict next value of PC
word f_predPC = [
	f_icode in { IJXX, ICALL } : f_valC;
	1 : f_valP;
];
```



### Decode

- 这部分没什么难的，主要是5种forw源和2个dest
- valP和valA合并，SelA单元根据icode确定将什么值输出到d_valA
- **5个转发源是有顺序的，根据顺序匹配；顺序就是在流水线上的顺序，越深的指令优先级越低；**

- [ ] 为什么越深的指令优先级越低？

### Execute

- 不是所有情况下都能更改CC，如果流水线更深处的指令出现异常，通过m/W_stat控制set_CC flag
- 为什么是m/W_stat？
  - M没用，内存访问单元处理后才可能产生异常m
  - 如果W和E在同一个时钟周期，那就需要W
  - W阶段不会产生异常，所以不如直接用W

- [ ] 和call, push, pop有关的需要更仔细地查看

```
################ Execute Stage #####################################

## Select input A to ALU
word aluA = [
	E_icode in { IRRMOVQ, IOPQ } : E_valA;
	E_icode in { IIRMOVQ, IRMMOVQ, IMRMOVQ } : E_valC;
	E_icode in { ICALL, IPUSHQ } : -8;
	E_icode in { IRET, IPOPQ } : 8;
	# Other instructions don't need ALU
];

## Select input B to ALU
word aluB = [
	E_icode in { IRMMOVQ, IMRMOVQ, IOPQ, ICALL, 
		     IPUSHQ, IRET, IPOPQ } : E_valB;
	E_icode in { IRRMOVQ, IIRMOVQ } : 0;
	# Other instructions don't need ALU
];

## Set the ALU function
word alufun = [
	E_icode == IOPQ : E_ifun;
	1 : ALUADD;
];

## Should the condition codes be updated?
bool set_cc = E_icode == IOPQ &&
	# State changes only during normal operation
	!m_stat in { SADR, SINS, SHLT } && !W_stat in { SADR, SINS, SHLT };

## Generate valA in execute stage
word e_valA = E_valA;    # Pass valA through stage

## Set dstE to RNONE in event of not-taken conditional move
word e_dstE = [
	E_icode == IRRMOVQ && !e_Cnd : RNONE;
	1 : E_dstE;
];
```

### Memory Access

- 这一步可能会产生异常，尤其是在读写内存时

### Write Back

- 写回到寄存器文件，没什么特殊的

### pipeline register control

- 在Fetch前stalling
  - 如果更深处有ret
  - load hazard
- 在Decode前stall
  - load hazard

- [ ] 为什么E寄存器为某些指令时会有冲突
- [ ] ？

```
################ Pipeline Register Control #########################

# Should I stall or inject a bubble into Pipeline Register F?
# At most one of these can be true.
bool F_bubble = 0;
bool F_stall =
	# Conditions for a load/use hazard
	E_icode in { IMRMOVQ, IPOPQ } &&
	 E_dstM in { d_srcA, d_srcB } ||
	# Stalling at fetch while ret passes through pipeline
	IRET in { D_icode, E_icode, M_icode };

# Should I stall or inject a bubble into Pipeline Register D?
# At most one of these can be true.
bool D_stall = 
	# Conditions for a load/use hazard
	E_icode in { IMRMOVQ, IPOPQ } &&
	 E_dstM in { d_srcA, d_srcB };

bool D_bubble =
	# Mispredicted branch
	(E_icode == IJXX && !e_Cnd) ||
	# Stalling at fetch while ret passes through pipeline
	# but not condition for a load/use hazard
	!(E_icode in { IMRMOVQ, IPOPQ } && E_dstM in { d_srcA, d_srcB }) &&
	  IRET in { D_icode, E_icode, M_icode };

# Should I stall or inject a bubble into Pipeline Register E?
# At most one of these can be true.
bool E_stall = 0;
bool E_bubble =
	# Mispredicted branch
	(E_icode == IJXX && !e_Cnd) ||
	# Conditions for a load/use hazard
	E_icode in { IMRMOVQ, IPOPQ } &&
	 E_dstM in { d_srcA, d_srcB};

# Should I stall or inject a bubble into Pipeline Register M?
# At most one of these can be true.
bool M_stall = 0;
# Start injecting bubbles as soon as exception passes through memory stage
bool M_bubble = m_stat in { SADR, SINS, SHLT } || W_stat in { SADR, SINS, SHLT };

# Should I stall or inject a bubble into Pipeline Register W?
bool W_stall = W_stat in { SADR, SINS, SHLT };
bool W_bubble = 0;
#/* $end pipe-all-hcl */
```



# Program Optimization

> `./demo/show_prog_opt.c`

## Intro

一些程序优化的例子：

- set_row1: 减少不变量的重复计算
- set_row2: 将耗时的乘法转变为加法
- get_row3: 减少不变量的重复计算
- lower: 可以减少不变量的重复计算，**但是编译器并不能确定循环中是否改变了字符串的长度，所以每次循环都会在条件中计算字符串的长度**
- sum_row: 可以减少内存IO和循环不变量； 但这么做是有风险的。 如果b恰好是a的某一列（B is mem alias of a col of A），那么就不应该优化; **编译器无法确定是否存在这种情况**

下面这些是编译器有可能优化的：

- **Code Motion：**如果同样的运算在循环中反复计算，可将其移动到循环之前
- Reduction in Strength：减少计算强度，比如乘法可被转化为加法/shift
- Share Common sub-expressions: 如果循环中出现了相同的变量，可以提前计算并共享

但有些可能是编译器无法优化的：

- 在一个循环中，改变字符串中的每个字符，但是每次循环都通过strlen获取长度；由于编译器不确定是否会改变字符串长度，所以可能无法优化；**小心，在循环条件判断中使用函数可能会增加时间复杂度**
- 存在**mem alias**：如果两个变量指向了同一个内存地址，编译器会不确定是否优化，因此会在内存-寄存器之间反复移动, 内存引用次数增加
- **procedure call**: 过程调用有可能会改变一些变量, 因此编译器通常不会优化这一点; 如果有需要可以**inline**, 或者**手动 Code Motion**

通用的优化方法：

- 乱序执行：如果CPU发现一个程序中的部分指令不是相互依赖的（data hazard, load/use hazard），就有可能会乱序执行：因为现代CPU可以同时运行若干条指令，不仅有流水线，还有超标量
- **循环展开：**在一个循环中处理多个值，可以减少对PC的操作和判断; 编译器有可能会自动循环展开
- 减少内存IO: 如果在循环中频繁IO, 那不如只在循环外IO一次

## Opt of Vector Element Loop

> 性能瓶颈可以分成两部分：
>
> 1. latency：一个指令从头到尾花的时间
> 2. throughput：cycle/issue两个指令的距离，*应该取决于时钟周期和多发射能力，比如CPU中有多个加法ALU*

### combine1: 最没有优化的基准程序

- 数据类型没有太大影响
- 处理每个元素花费的时钟周期都很长
- 开了O1很快

### combine4：使用了以上的一些优化，优化措施包括：

1. 减少proc call
2. 减少无用的index检查
3. 使用临时变量减少内存IO



### unroll_2: 2级循环展开

- 对于int，可以接近lat 极限，因为接近于不断执行int

### unroll_2_opt:

```
tmp = (tmp OP val1) OP val2;
tmp = tmp OP (val1 OP val2);
```

- 这个改进可以进一步减少消耗时间
- 旧方式中必须计算_tmp = tmp OP val1, 然后tmp = _tmp * val2，然后计算下一组；每一组需要2个乘法，并且所有的乘法之间都是相互依赖的；
- 新方式中，两种计算可以指令级并行：_tmp=val1 * val2, tmp = _tmp * tmp; 第二个乘法和下一组的第一个乘法没有数据依赖；如果循环足够长，这样做可以将性能提高接近一倍

**WARNING: 浮点数不一定满足结合律？可能有大数吃小数的风险**

### unroll_2_opt_div2:

将循环分成若干组（例如奇数和偶数分别得到tmp1和tmp2），最后把所有结果结合起来。这样可以更充分地利用多发射/ALU资源，接近throughput极限。

### unroll_L_divK:

可在两个方面都更接近极限

### %xmm and AVX 

通过向量化可以一次做多个运算。



## Debuff of Optimization

过度优化的debuff:

- 寄存器溢出: 所需寄存器数量超过实际值, 导致更多内存IO
- 分支预测, 失败惩罚



## Cache IO

内存读写的延迟通常在50-100ns，而CPU频率（5GHz）对应的时钟周期是0.2ns，所以内存真的是个很慢的设备——相比之下硬盘更慢。

为了尽量减少IO瓶颈，计算机发展出了多级缓存。如果CPU需要某个数据，他会一级一级地查找各级缓存设备，可能有 hit 或者 miss。

K+1级别的block要储存到K级的block时，映射关系可以是取余：但这也意味着如果要访问的数据满足某种特定的关系，可能会一直miss；

### How to read? (direct-mapped)

- 地址有m位，这样就有$2^m$个地址
- cache有$S=2^s$个set
- 每个set有E个line
- 每个line的组成包括：$B=2^b$字节的数据块，1 bit的有效位，t个标记位 $t=m-(b+s)$
- cache的容量为$C = S\times E\times B$ 字节
- 对于一个m位的地址，我们将其划分为tag(t), set(s), block(b)三部分
  - 当查询一个地址对应的值是否在cache中时
  - 首先从地址中取出set bits，在cache中找到对应的set
  - 然后从地址中取出tag bits，在set中找到对应的line
  - 如果这个line对应的v bit是1，通过b可以确定在B个字节中的数据块的字偏移
  - 从偏移开始的地方读取字节

---

存储设备到cache的映射：

- 对于一个内存地址，其s和t位可映射到cache中；特别的，如果E=1，叫做 direct-mapped cache（下面的很多地方都以这种cache为例）；
- 根据s和t位，会发现某一些内存被映射到了同一个cache line，这把内存划分成了若干个 block，每个block中包含了若干个内存位置
- 同时注意到很多个block都会对应到同一个line

---

- 如果s和t发现cache hit，那就读取
- 如果发现cache miss，那就下一级存储设备中读取；这个问题对于直接映射的cache非常好解决，直接替换就行；
- 如果cache miss，就会一次性把整个block都取出来，放到cache中
- 如果cache hit，就根据offset读取对应的字节

在某种特殊情况下，cache总是 miss，例如：

- 每个set只有1个line
- 多个blocks都对应了同一个set，同时因为只有一个line，所以这个set只能储存一种 t 对应的block；
- 如果一个程序要同时处理多个blocks中的2个，在处理第一个block时会把对应的若干内存地址都存入内存；
- 在处理第二个block时，由于对应的set/line中的tag不一样，所以会再次读取所有的block；
- 如果一直循环下去，就会不断重复这样的过程，**thrashing**
- 避免的方法：在每个数组后补充B字节的padding，这样就能避免两个数组有相同的set/line

### How to read? (set-associative)

以上的thrashing是因为E=1，内存地址中s相同的各个blocks中只能同时储存一个；如果E>1就好了，这种cache称为 E-way set associative cache。

- Pro：这样s相同，但是t不同的可以同时储存
- Con：每次查询是否hit都要查看一个set中所有的E-way，电路的成本高，复杂——但总的来说还是有益的

如果s相同，但是t没有命中，就会根据LRU来确定替换哪个line

### How to read (fully associative)

$E=C/B$，一个set包含所有的line。

成本非常高，只适合做小型cache，例如虚拟内存中的翻译备用缓冲器。



### How to write

如果 write hit，高级cache就会立即更新；但如何更新给低级cache呢？

- write-through：立即写给低级cache——这会引起巨大的bus traffic
- **write-back**：尽可能地推迟，直到不得不替换——减少bus traffic，但是增加复杂度，每个line必须有一个dirty bit，表明这个line被修改过（这样等到被替换时才知道要write-back）

如果 write miss呢？

- **write-allocate**：把低级cache读到高级cache；可以利用程序的空间局部性，但每次miss都得从低级cache读
- not-write-allocate：直接写到低级cache里



## Cache Struct

很多cache分成两派：

- i cache，只储存指令（大概率也是只读）
- d cache，只储存数据
- 两者都储存：统一cache

分开有好处，可以做不同的优化。

- block size的影响：通常block size越大，越能充分利用空间局部性；但同时line变少，并且miss 惩罚也更大；
- E的影响：E大的话复杂，但减少了thrash的可能；
- 层次越低，miss的惩罚就越大

## Cache Friendly Code

- 关注经常使用的部分：尤其是循环
- 步长为1还是比较好的
- 反复引用局部变量是好的
- 在访问二维数组时（把内存看成一个大的一维数组），逐行扫描是好的，逐列扫描的miss率几乎是0

## Cache Perf

== TODO ==

结构为:

```
load unit  ---  store unit (buffer)
    |               |
       C  A  C  H  E
```

- load: 检查store unit的buffer, 有无相同地址
- store: buffer包含已经被发射到存储单元而又还没有完成的存储操作的地址和数据; 存储时会同时进行两项操作: 存储到buffer和内存





# TEMP: ShellLab





# System I/O

## open/close, read/write

- seek可以改变文件光标的位置
- fd: 小整数, 用来标识正在使用的文件; OS有最大数限制, shell启动的每个进程的fd 0-stdin, 1-stdout, 2-stderr
- 文件的open和close都可能报错
- 读文件需要buffer
- read/write函数复制最多n个字节到buffer; 但也可能会返回负数error, 例如不足值, 比如:
  - 遇到EOF
  - 从terminal读取一行
  - 读写网络socket
- 但也有些情况不会触发不足值
  - 从磁盘文件读到EOF
  - 写到磁盘
- 如果read/write返回0, 说明是一个EOF
- 如果大于0, 是正常情况

## RIO

自动处理不足值的情况, 尤其是在网络IO中. 

- rio_read如果没读够值就会一直读, 除非遇到EOF, 或者某种signal, 或者报错
- buffered IO, 例如先从文件中读一些到缓存, 如果缓存不满就接着读

## metadata

data about data, 例如文件修改时间, 创建时间等

## Shared File in Linux

有3个数据结构用来表示内核中打开的文件

1. descriptor table: 每个进程都有, 以fd作为index, 每个都指向 file table entry
2. file table: 打开的文件的集合, 所有进程共享这个表, 其中包括文件位置 (cursor), 引用计数器, 以及v-node指针
3. v-node table: 所有进程共享, 包含stat结构中的大部分信息

共享体现在:

1. 对于同一个进程, 不同的fd可以对应不同的file table enrty, **并且这两个entries可以指向同一个文件的不同位置**
2. 父子进程的fd表可以指向同一个file table

## IO Redirection

dup2函数复制旧的fd table entry给新的

# VRAM

## Feature

1. 将主存看作是磁盘的cache
2. 抽象, 简化内存管理
3. 保护每个进程的**地址空间**不被其他进程破坏

## Why do we need VM

1. 如果直接使用物理地址, 可能会不安全, 例如多个进程使用同一个地址
2. 物理内存可能不足, 需要使用一部分磁盘作为内存空间
3.  内存可能是碎片化的, 如果某个程序需要大片的, 连续分配的内存, 就有可能无法分配

---

为了解决以上的三个问题,出现了虚拟内存这一层抽象概念, 对CPU和程序封装了底层的DRAM+MMU+Disk, 而且还可以管理进程使用的内存空间, 避免冲突. 

虚拟内存像是一个介于DRAM和Disk之间的虚拟概念, 其中DRAM可看作是VM的Cache. 

这个想法看起来低效, 但因为程序有局部性, 所以这个Cache确实有用. 

同时也可实现连续分配内存: 在虚拟内存上是连续的, 但实际可能分散地映射到物理内存上

也可以实现进程间数据共享, 两个进程的页表可以映射到同一个物理地址

## Addressing

- CPU使用一个虚拟地址访问主存, 通过MMU翻译形成物理地址
- 主存上的每个字节都有一个虚拟地址空间和一个物理地址空间



## Caching, Page Table

虚拟内存在概念上是一个磁盘上的连续数组, 分成很多Pages (VP); 有些VP是; 

- unallocated: 还没内容, 所以也不在磁盘上 (节约空间)
- uncached: 在磁盘上, 但是不在DRAM上
- cached: 在磁盘也在DRAM上, 并且有一个映射

Page的大小必须权衡, 如果太大, 就会降低Page数量; 如果太小, 就可能不命中

---

Page Table可用来管理虚拟内存, 如果命中的话决定虚拟页和物理页的映射关系, 或者不命中的话决定存放在磁盘的什么位置, 以及如何替换DRAM上的位置

每个进程都有Page Table, 由操作系统维护; 每个Entry都包括1和valid bit和disk address; valid bit表明是否被缓存, address中的内容表明了一个地址 (DRAM或者磁盘).

---

如果访问一个Virtual Address, 遇到Page Hit的情况, 就会返回DRAM上的地址; 

如果Page Fault, 就会触发一个系统中断, PageFault; 系统会置换页面: 将一个已缓存的Page, 和当前需要但是未缓存的交换一下 (swapping, paging); Page Table中相应的映射关系也要更改; 此后重新执行该条语句, 就不会触发Page Fault了

## Manage & Protect

OS给每个进程分配一个独立的页表（**一个独立的虚拟地址空间**），不同页表的同一index可以指向相同/不同的物理内存页面。这允许每个进程的内存都使用同样的格式（例如所有代码段都从`0x400000`开始）

这种机制可以简化链接、加载、共享、内存分配（不需要物理连续的内存地址）。

---

实际上每个PTE还包含super, RWX位, 表明这个内存可以被如何使用



## Address Translate

### General Case

以下是一些概念：

- TLBI: TLB Index
- TLBT: TLB tag
- TLB: Translation Lookaside Buffer: 内存翻译结果的缓存

- VPO: Virtual Page Offset
- VPN: Virtual Page Number
- PPO/PPN: Physical Page

---

寻址的过程：

1. CPU有一个寄存器，指向页表
2. 虚拟地址n位 (64位)，2^10=Kb, 2^20=Mb, 2^30=Gb, 2^33=GB, 2^47=16*1000 GB
3. n位的虚拟地址中, 前(n-p)位是VPN, 后p位是VPO (==PPO)
4. m位的物理地址中, 前(m-p)位是PPN, 后p位是PPO
5. **PPN相同的物理内存地址都属于一个page, 所以后p位和page大小相关, 4KB的page == p有6位**
6. VPN作为页表的index, 查找某个PTE, 找到valid bit和PPN

### TLB, L1-Cache

以上的过程可能会多次查询页表, 所以出现了TLB

每一行TLB的组成:

- 最低p位VPO
- 中间t位TLBI
- 最高n-p-t位TLBT

TLB是单独的一个缓存, 如果没命中就到L1-Cache中查找

### Multi Level Paging

如果每个进程都是用一个一级页表, 那就会占用过大的内存; 一个解决方法是使用多级页表. 

例如将虚拟内存分成若干chunk, 每个chunk 4MB, 都由若干page组成; 一级页表负责管理每个chunk, 只有chunk被使用了才会分配内存空间生成二级页表, 否则就可以减少内存消耗. 

一级页表常驻主存, 二级页表根据使用情况可以放在磁盘上, 这样进一步减少内存占用. 

现在虚拟地址可被划分为若干个VPN+VPO, 若干个VPN分别指向不同层级的页表

### Instance

**虚拟地址14位, Page 4KB**, 则14位地址分成

| VPN: TLBT | VPN: TLBI | VPO       |
| --------- | --------- | --------- |
| 6位       | 2位, 0-3  | 6位, 0-3f |

**TLB缓存的结构:** 以内存地址的TLBI判断set (4 sets), 每个set包括4 Line, 相同TLBI的虚拟内存TLBT存储在set中, 但最多只能储存4个. 缓存的实际内容是PPN

**页表:** 建立VPN到PPN的映射, 共有2^8个PTE

**物理地址12位**, 分成: 

| PPN (CT) | PPO: CI | PPO: CO |
| -------- | ------- | ------- |
| 6位      | 4位     | 2位     |

**L1-Cache:** 16个组 对应CI; 每个组 1 Line; 6位作为CT; 同一时刻中Cache的每一行中储存了4个block的结果 (相同CT和CI的地址有4个); 如果miss就必须evict这一行, 换成其他的tag

---

一个实际的例子: 

- CPU读取`0x03d4 (00 0011 1101 0100)`
- 查找TLB, set=3, tag=3; 
- TLB命中, 对应PPN `0x0D`
- 组合成地址`0x0D + 0b 010100 = 0x0354 (0011 0101 0100)`
- 查找L1-Cache, set=5, tag=0x0D, offset=0
- L1-Cache命中, 内存中的内容为0x36

## Linux VM System

![](https://i.sstatic.net/R4tVn.png)

虚拟内存的高位属于内核，其中有3部分： 

1. 进程相关，每个进程都不同
2. 直接映射的物理内存， 每个进程都一样（可能是映射到设备）
3. 内核代码

虚拟内存包括若干个段（segment/area），每个段是连续的allocated VM chunks；

![](https://i.sstatic.net/QU2ye.png)

每个进程都对应一个task struct对象，其中的mm struct描述了虚拟内存相关的信息, 其中mmap是一个链表，内容是该进程使用的内存段

---

Linux Page Fault

有的时候会报段错误，因为进程访问一个地址前，会先查看mmap对应的链表，看地址是否在某个段里。如果不在就报错。

如果访问模式不合法，例如读写模式不匹配，也会报错终止

swap, 交换需要的page到内存

## Memory Mapping

- VM segment可以映射到磁盘文件
- 映射到匿名文件（不是真的文件，全是二进制0）
- CoW实现共享对象以及私有拷贝
- fork时创建新的task对象，并把所有内存区域标记为只读和cow，有进程想写入了才会复制，创建新的page
- execve将新的进程替换当前的进程
- **mmap函数**创建新的虚拟内存区域，并把对象映射过去

## malloc

动态内存分配器维护着 heap，从.data.bss开始，一直向上增长；kernel维护一个**brk指针**指向堆顶。

堆由很多block构成，**block也是连续的chunks，要么是allocated，要么是free**

malloc返回一个指针，对应的内存块有内存对齐。

**sbrk函数**用于扩展或者收缩堆，成功的话就返回旧值。

**free函数**释放对应的内存，但这个内存必须是通过malloc分配的，否则就是一个未定义行为

## allocator

要求：

- 处理任何请求序列
- 立即响应
- 只使用堆
- 对齐
- 不修改已经分配的块

内存吞吐量和利用率是矛盾的两个指标，如果把内存当作无穷大时吞吐量最大，但此时利用率低。造成问题的原因是内存碎片化，

碎片有两种：

- 内部碎片：为了内存对齐
- 外部碎片：已分配区域之间的空白

## Implicit Idle NodeList

隐式空闲链表是一个数据结构，用来区分块的边界。前32 bits为这个块的header，包括29 bits的块大小（后3 bits为0，内存对齐）以及 3 bits的块信息（是否被分配）。

header之后是payload，可能还有padding。

称之为隐式链表是因为并不是传统的通过next找到下一个块，而是通过块大小来找。链表的结束是一个已分配，但是分配大小为0的块。

### Placement

有多种策略，例如：

- first fit: 从链表开头找第一个
- next fit: 从上次位置开始找第一个
- best fit: 检查所有空闲块，选择最合适大小的

如果没有合适大小的块，就需要sbrk，申请新的堆内存

### Coalescing

如果释放了一个块，和他相邻的块都是空闲，就会形成fault fragment——本来是一个大空闲块，硬是成碎片了。

为了解决这个问题，可以Immediate Coalescing，但这可能会导致thrashing（立即合并，又立即分配）；也可以Deferred Coalescing，如果某个分配失败，扫描链表并且合并。

合并的另一个问题是，不知道前面的块在哪里开始。一个解决方法是使用boundary tag，在每个块的末尾加一个header的复制，这样在合并的时候可通过当前块的header找到上一个块的footer，进而找到上一个块的开头。

footer也会占用额外的内存，所以一种优化是：如果一个块被分配了，就不需要footer，只有当需要被free时才会添加footer

还可以在一个块的bits中包含前一个块的分配状态

## Implement of an Allocator

- 堆起始位置指针开始有个4B的空白, 这个空白是为了实现内存整体的8B对齐, 和最后的epilogue block对应; 
- 紧接着是**prologue block**, 8/1-header, 8/1 footer
- 然后是若干个普通 blocks, 带有header, 如果等待合并才有footer; 
- *block的payload似乎也应该是8B对齐的, footer可能成为额外的空间*
- 结尾是一个epilogue block, 0/1 (32 bits, 4B)



### macro

- Word Size, Double Word, Chunk (4K)
- **PACK**, 将29 bits的size (后3 bit为隐式的8B对齐, 全0意味着必须是8的倍数) 和3bits的 alloc status打包
- GET PUT, 强转指针为WordSize指针(4 Bytes), 一次操作4 Bytes
- GET_SIZE, mask掉后3 bits; GET_ALLOC, 取最后一位
- HDRP, 给block pointer强转 1Byte的指针, -4, 相当于-32, 指向block header
- FTRP: header + get_size - 2B; get_size获得的值可能是任意字节, 所以强转 char*
- NEXT_BLKP: `(char*)(bp) + GETSIZE((char *)bp - WSIZE) `
- PREV_BLKP: `(char*)(bp) - GETSIZE(char* bp - DSIZE)`

### mm init

从sbrk申请地址4 * 4B, PUT 4B空白, 8B prologue block, 4B epilogue block

heap_listp: 总是指向prologue block 的payload/footer

extend heap by a chunk (4096 Bytes, 4KB), 创建初始的空闲块

### extend_heap

- 将申请的words向上取整, 调用sbrk, 返回一个bp
- 初始化bp对应的header (替换了旧的epilogue block) , 初始化footer
- 生成新的epilogue block
- coalesce当前block

### coalesce

- 获取前后两个块的alloc状态
- 获取当前块的size

分成几种情况: 

1. 前后都alloc, 什么也不干
2. 仅仅后面的free: 获取后面的size, 修改header, 再修改footer; **这里存在先后关系, 因为查找footer是根据bp+header size确定的**
3. 仅仅前面的free: 修改当前block的footer, 查找前一个block的header并且修改
4. 前后都free: 找到前后block的header/footer, 修改内容

这种方法可以忽略边缘问题 (如果当前block在最开头/结尾), 因为prologue和epilogue都是allocated



### mm_free

- 将当前块的header和footer描述为未分配
- coalesce

### malloc

- 调整block size, 向DWORD取整
- **`asize = DSIZE * ((size + (DSIZE) + (DSIZE-1)) / DSIZE) ;`**
- size=[0, +infty)
- size+2D-1=[2D-1, +infty]
- / = 1 if size=0, else >1
- 遍历找到合适的空间
- 没找到就extend



## Explicit Free NodeList

一个显式的双向链表, 可以标记所有的空闲块, 这样的话即使是On, 也只需要遍历空闲的块

如何维护链表: 

- LIFO, 将空闲块放在head
- **按照地址顺序:** 

分离存储: 将块的大小分成等价类 (例如按照2的幂), 每个大小是一个单独的链表, 当需要读写的时候, 就单独找对应的链表. 

- 好处是每个链表中大小都相等, 所以没有分割和合并; 只需要单向链表
- 缺点是容易造成碎片

**分离适配**

> [内存管理：显式空闲链表 - 月踏的文章 - 知乎](https://zhuanlan.zhihu.com/p/378352199)

系统维护一个array, 每个array是一个链表, 但是这个链表里的block的size都在一个范围里, 而不是固定值. 

为了分配一个chunk，要先确定使用请求的大小在哪一个空闲链表上，然后再在所在的链表上使用first fit、last fit、best fit这些算法来确定具体分配哪个chunk，以上面图5为例，分两种情况讨论：

1. 相应list为空：假如用户请求2049个字节，加上4字节的header，再进行8字节对齐，实际需要分配2056个字节，而[2049,4096]这个list为空，这时候需要从系统中申请一块足够大的空间，假如申请2056大小的空间，然后分成2056和2040两个chunk，把2056的chunk返回给用户，2040的chunk维护到相应的list上。
2. 相应list不为空：假如用户请求1601个字节，加上4字节的header，再进行8字节对齐，实际需要分配1608个字节，这时候需要查询[1024,2048]这个list，里面只有一个2048大小的chunk，那就把这个chunk拆分成1608和440两个chunk，把1608的chunk返回给用户，440的chunk维护到相应的list中。

释放allocated chunk的时候要进行合并，并把合并后的chunk维护到相应的list上，合并过程在[隐式空闲链表](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzg5MzU4NTU5Nw%3D%3D%26mid%3D2247483842%26idx%3D1%26sn%3D5bf65cab40a6243f462bfcf433394294%26chksm%3Dc02dd010f75a59064176fc681a53a2594f23b5760185c625070ff7e27a1c3a5ee9dc272b7371%26scene%3D21%23wechat_redirect)中已经说过，这里不再赘述了。分离适配方法是一种常见的选择，malloc就用到了这个方法，当然具体实现比这里讲的要复杂的多的多，malloc也没有只使用这一种算法，后续讲malloc实现的时候再具体讲。

![](https://pic3.zhimg.com/v2-9c4bf602289ce7f948d2d7b1f2e39a88_1440w.jpg)

**伙伴系统** 

在分离适配的基础上, 每个大小类都是2的幂. 如果分配一个块, 就向上取整在2的幂, 然后去找比这块大一点的块, 有可能的话就二分. 

给定地址和块的大小，很容易计算出它的伙伴的地址

![](https://pic4.zhimg.com/v2-f5b2cddb3db5194414660c8e6e4ba939_1440w.jpg)

## GC





## Mem Fault

- null ptr
- 指针指向的地址没有初始化
- Stack Buffer Overflow
- 指针和指向的对象不一样大!
- for循环写错, 越界
- 操作符优先级
- 指针的加减其实是数字 * 大小
- 在函数里引用不合法 (生命周期结束)的变量
- 引用已经free的内存
- mem leak









